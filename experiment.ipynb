{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7deb7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83a0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERPLEXITY_API_KEY = os.getenv(\"Perplexity_API_Key\")\n",
    "GOOGLE_GEMINI_API_KEY = os.getenv(\"Gemini_API_Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0220603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fef0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the best payment gateways for developers in the UK?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c83104cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "chat_url = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"sonar-pro\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Be precise and concise.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \" + PERPLEXITY_API_KEY,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "chat_response = requests.post(chat_url, json=payload, headers=headers)\n",
    "\n",
    "print(chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd951b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794f7344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04779f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "perpelixity_response_text = chat_response.json()['choices'][0]['message']['content']\n",
    "perpelixity_response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e736f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfb97f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_client = \"Stripe\"\n",
    "gemini_prompt = f\"\"\"\n",
    "You are an expert data extractor.\n",
    "\n",
    "The following text delimited by triple askticks is a user query for Perplexity AI:\n",
    "\n",
    "***\n",
    "{query}\n",
    "***\n",
    "\n",
    "And the following text delimited by triple backticks is the response from Perplexity AI for the query above:\n",
    "\n",
    "```\n",
    "{perpelixity_response_text}\n",
    "```\n",
    "\n",
    "Your task is to determine if the target client '{target_client}' is mentioned in the response from Perplexity AI, by following these steps:\n",
    "Step 1. Check if the target client '{target_client}' is mentioned in the response.\n",
    "Step 2. Extract all the competitors in the response.\n",
    "Step 3. If client '{target_client}', determine the rank position of the target client '{target_client}' among the competitors extracted, using the following rule:\n",
    "    - If the target client '{target_client}' is mentioned and a ranking is explicitly list in the response, such as \"1. PayPal, 2. Stripe\", return the ranking of the target client listed.\n",
    "    - If the target client '{target_client}' is mentioned but no explicit ranking is provided, return 0 for rank position.\n",
    "    - If the target client '{target_client}' is not mentioned, return None for rank position.\n",
    "\n",
    "\n",
    "Return your response as a single JSON object which strictly following the JSON schema given in this request\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c673b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingResponse(BaseModel):\n",
    "    is_visisble: bool = Field(\n",
    "        description=f\"Whether if the target client '{target_client}' is mentioned in the response\"\n",
    "    ),\n",
    "    competitors: List[str] = Field(\n",
    "        description=\"List of competitors extracted from the response. If none, return an empty list.\"\n",
    "    )\n",
    "    rank_position: int = Field(\n",
    "        description=\"Rank position of the target client among competitors following the ranking rule described in Step 3 in the prompt.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7918a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"is_visisble\":true,\"competitors\":[\"Stripe\",\"Adyen\",\"Braintree (PayPal)\",\"Square\",\"Checkout.com\",\"Opayo (Sage Pay)\"],\"rank_position\":1}\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "gemini_response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=gemini_prompt,\n",
    "    config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_json_schema\": RankingResponse.model_json_schema(),\n",
    "    },\n",
    ")\n",
    "\n",
    "print(gemini_response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
